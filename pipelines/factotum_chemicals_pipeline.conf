#
# to run from the /factotum_elasticsearch directory: 
# /usr/local/bin/logstash -f ./pipelines/factotum_chemicals_pipeline.conf


input {
    jdbc {
        # ${JDBC_DRIVER_LIBRARY} = full path to mysql-connector-java-*.jar
        jdbc_driver_library => "${JDBC_DRIVER_LIBRARY}"
        jdbc_driver_class => "com.mysql.jdbc.Driver"

        # ${SQL_HOST} = hostname:port of SQL server
        # ${SQL_DATABASE} = database name on SQL server
        # ${SQL_USER} = SQL server username
        # ${SQL_PASSWORD} = SQL server user password
        jdbc_connection_string => "jdbc:mysql://${SQL_HOST}:${SQL_PORT}/${SQL_DATABASE}"
        jdbc_user => "${SQL_USER}"
        jdbc_password => "${SQL_PASSWORD}"
        parameters => {}
        statement => "select 
        rc.id,
        'Chemical' as facet_model_name,
        extracted_text_id as data_document_id,
        (SELECT COUNT(*) 
        FROM dashboard_productdocument 
        where document_id = extracted_text_id) as product_count,
        raw_cas,
        raw_chem_name,
            dss.sid,
            dss.true_cas,
            dss.true_chemname
        from dashboard_rawchem rc
        left join dashboard_dsstoxlookup dss on rc.dsstox_id = dss.id "
    }
}
#filter {
##}
output {
    elasticsearch {
        # ${ELASTICSEARCH_HOST} = hostname:port of Elasticsearch instance
        hosts => ["${ELASTICSEARCH_HOST}"]
        index => "factotum_chemicals"
        document_id => "%{id}"
    }
    # stdout {
    #     codec => rubydebug
    # }
}